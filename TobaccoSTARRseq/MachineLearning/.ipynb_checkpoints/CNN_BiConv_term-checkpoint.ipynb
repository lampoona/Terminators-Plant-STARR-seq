{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adMcH2OlKe22"
   },
   "source": [
    "# Building a convolutional neural network model to predict terminator strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tof4uKXNKe23"
   },
   "source": [
    "## Import modules and define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VstvDQfjKe24"
   },
   "source": [
    "Import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102053,
     "status": "ok",
     "timestamp": 1649778903312,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "vBluNFcmKe25",
    "outputId": "c54795db-d2d1-4b75-fca0-80b5f98f3a37"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow.keras.layers as kl\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from io import TextIOBase\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArIMNrIbKe27"
   },
   "source": [
    "Enable GPU memory growth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1649778908068,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "Ql4RC57IKe27",
    "outputId": "ae152329-cf9e-483e-81e0-10d76e118471",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:27:49.939337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:49.979884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:49.980318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:49.981031: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-23 09:27:49.982225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:49.982644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:49.983014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:50.777962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:50.778570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:50.778610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 09:27:50.779108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-23 09:27:50.779164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2113 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlZ_iV0IKe28"
   },
   "source": [
    "Define a function to one-hot encode the DNA sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1649778993109,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "srlpv8lhKe29"
   },
   "outputs": [],
   "source": [
    "BASE_1HOT = OrderedDict((\n",
    "    (\"A\", np.array([1, 0, 0, 0])),\n",
    "    (\"C\", np.array([0, 1, 0, 0])),\n",
    "    (\"G\", np.array([0, 0, 1, 0])),\n",
    "    (\"T\", np.array([0, 0, 0, 1]))\n",
    "))\n",
    "\n",
    "def one_hot_encoding(seq):\n",
    "    \"\"\" one-hot encodes a DNA sequence \"\"\"\n",
    "    encoded = np.zeros(shape = (len(seq), 4), dtype = 'int8')\n",
    "    for i, base in enumerate(seq):\n",
    "        try:\n",
    "            encoded[i, :] = BASE_1HOT[base]\n",
    "        except KeyError:\n",
    "            logging.error(\n",
    "                f\"Unrecognized base encountered during one-hot encoding: '{base}'\"\n",
    "            )\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk_OF2yjKe29"
   },
   "source": [
    "## Load and convert the data to the required format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mivI9eaiKe2-"
   },
   "source": [
    "Load the experimental data and split into training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13009,
     "status": "ok",
     "timestamp": 1649778926182,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "orqfYcyfKe2_"
   },
   "outputs": [],
   "source": [
    "data_term = pd.read_csv('terminator_data.tsv', sep = '\\t', header = 0)\n",
    "\n",
    "data_train = data_term.query('set == \"train\"').reset_index(drop = True)\n",
    "data_test = data_term.query('set == \"test\"').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq3tVe3KKe3A"
   },
   "source": [
    "One-hot encode the terminator sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 129647,
     "status": "ok",
     "timestamp": 1649779131049,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "YkB3bR9nKe3A"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff408d7dff1b4be5b94329f8886f4718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding training sequences:   0%|          | 0/48172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ffa6bce0dd426b901b57e54718122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding test sequences:   0%|          | 0/5318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sequences = np.stack(tuple(map(one_hot_encoding, tqdm(data_train['sequence'], desc = 'Encoding training sequences'))))\n",
    "test_sequences = np.stack(tuple(map(one_hot_encoding, tqdm(data_test['sequence'], desc = 'Encoding test sequences'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUPCbyZbKe3B"
   },
   "source": [
    "Convert the enrichment value to an array of the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1649779131051,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "yA1TEV8aKe3B"
   },
   "outputs": [],
   "source": [
    "train_enrichment = np.array(data_train[['enrichment']]).reshape(-1, 1)\n",
    "test_enrichment = np.array(data_test[['enrichment']]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8ex9rjXKe3B"
   },
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyczolwbKe3C"
   },
   "source": [
    "Define a bidirectional convolutional layer stack, inspired from DeepGMAP (https://doi.org/10.1371/journal.pone.0235748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649779131052,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "ClW7sCTkKe3C"
   },
   "outputs": [],
   "source": [
    "class BiConv1D(kl.Layer):\n",
    "    def __init__(self, filters, kernel_size, layers = 2, stride = 1, dropout_rate = 0.15):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        if layers < 1:\n",
    "            raise ValueError(\"At least one layer needed\")\n",
    "        self.layers = layers\n",
    "        if (dropout_rate < 0) or (dropout_rate > 1):\n",
    "            raise ValueError(\"Dropout rate must be a float between 0 and 1\")\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernels = []\n",
    "        self.biases = []\n",
    "        for layer in range(self.layers):\n",
    "            self.kernels.append(self.add_weight(\n",
    "                f\"kernel{layer}\",\n",
    "                shape = (self.kernel_size, input_shape[-1], self.filters),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.GlorotUniform()\n",
    "            ))\n",
    "            self.biases.append(self.add_weight(\n",
    "                f\"bias{layer}\",\n",
    "                shape = (self.filters,),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.Zeros()\n",
    "            ))\n",
    "\n",
    "    def call(self, input):\n",
    "        # first layer\n",
    "        x_fwd = tf.nn.conv1d(input, self.kernels[0], stride = self.stride, padding = 'SAME')\n",
    "        x_fwd = tf.add(x_fwd, self.biases[0])\n",
    "        x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "        x_rev = tf.nn.conv1d(input, tf.reverse(self.kernels[0], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "        x_rev = tf.add(x_fwd, self.biases[0])\n",
    "        x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "        \n",
    "        # subsequent layers\n",
    "        for layer in range(1, self.layers):\n",
    "            x_fwd = tf.nn.conv1d(x_fwd, self.kernels[layer], stride = self.stride, padding = 'SAME')\n",
    "            x_fwd = tf.add(x_fwd, self.biases[layer])\n",
    "            x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "            x_rev = tf.nn.conv1d(x_rev, tf.reverse(self.kernels[layer], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "            x_rev = tf.add(x_fwd, self.biases[layer])\n",
    "            x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "        \n",
    "        return tf.math.add(x_fwd, x_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypwIsENSKe3D"
   },
   "source": [
    "Define a function to build the bidirectional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649779131054,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "KyyxdULCKe3D"
   },
   "outputs": [],
   "source": [
    "def build_bidirectional_model(motif_kernel: np.ndarray):\n",
    "    # motif_kernel.shape[2] is filters, shape[0] is kernel size\n",
    "    inputs = kl.Input((170, 4))\n",
    "    x = BiConv1D(filters = motif_kernel.shape[2], kernel_size = motif_kernel.shape[0], layers = 2)(inputs)\n",
    "    x = kl.Conv1D(filters = 128, kernel_size = 13, padding = 'same', activation = 'relu')(x)\n",
    "    x = kl.Dropout(0.15)(x)\n",
    "    x = kl.Flatten()(x)\n",
    "    x = kl.Dense(64)(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Activation('relu')(x)\n",
    "    outputs = kl.Dense(1)(x)\n",
    "    model = k.Model(inputs = inputs, outputs = outputs, name = \"BiDirectionalCNN\")\n",
    "    # initialize first layer kernel with motifs\n",
    "    model.layers[1].kernels[0].assign(motif_kernel)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WqSMje6Ke3E"
   },
   "source": [
    "Initialize the kernal weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1649779131371,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "Obil7v0KKe3E"
   },
   "outputs": [],
   "source": [
    "kernel = k.initializers.GlorotUniform()(shape = (13, 4, 128)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV5xzV_KKe3E"
   },
   "source": [
    "Build and compile the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1649779131662,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "jD41TlwCKe3F"
   },
   "outputs": [],
   "source": [
    "model = build_bidirectional_model(kernel)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['mean_squared_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-6QPCj-Ke3F"
   },
   "source": [
    "Define training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1649779131663,
     "user": {
      "displayName": "Tobias Jores",
      "userId": "03787875090787144031"
     },
     "user_tz": 420
    },
    "id": "c8OMVO3oKe3G"
   },
   "outputs": [],
   "source": [
    "earlyStop = k.callbacks.EarlyStopping(patience = 5)\n",
    "reduceLR = k.callbacks.ReduceLROnPlateau(patience = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEBeQHiWKe3G"
   },
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RU2RWPsDKe3G",
    "outputId": "6ceb8b05-c1c6-4301-9610-4428efa73b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:27:57.401207: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-07-23 09:27:58.273395: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-23 09:27:58.509366: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-23 09:27:58.509447: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/339 [..............................] - ETA: 9s - loss: 12.8779 - mean_squared_error: 12.8779 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:27:58.968781: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-23 09:27:58.968853: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - ETA: 0s - loss: 1.4188 - mean_squared_error: 1.4188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:28:11.496973: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.86GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-23 09:28:11.497043: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.86GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 17s 42ms/step - loss: 1.4188 - mean_squared_error: 1.4188 - val_loss: 3.1621 - val_mean_squared_error: 3.1621 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.4801 - mean_squared_error: 0.4801 - val_loss: 0.6216 - val_mean_squared_error: 0.6216 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "339/339 [==============================] - 12s 35ms/step - loss: 0.4255 - mean_squared_error: 0.4255 - val_loss: 0.4615 - val_mean_squared_error: 0.4615 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.3882 - mean_squared_error: 0.3882 - val_loss: 0.4849 - val_mean_squared_error: 0.4849 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.3634 - mean_squared_error: 0.3634 - val_loss: 0.4970 - val_mean_squared_error: 0.4970 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.3477 - mean_squared_error: 0.3477 - val_loss: 0.5987 - val_mean_squared_error: 0.5987 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "339/339 [==============================] - 11s 34ms/step - loss: 0.2984 - mean_squared_error: 0.2984 - val_loss: 0.3692 - val_mean_squared_error: 0.3692 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2864 - mean_squared_error: 0.2864 - val_loss: 0.3605 - val_mean_squared_error: 0.3605 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2815 - mean_squared_error: 0.2815 - val_loss: 0.3709 - val_mean_squared_error: 0.3709 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2729 - mean_squared_error: 0.2729 - val_loss: 0.3783 - val_mean_squared_error: 0.3783 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2719 - mean_squared_error: 0.2719 - val_loss: 0.3653 - val_mean_squared_error: 0.3653 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2593 - mean_squared_error: 0.2593 - val_loss: 0.3588 - val_mean_squared_error: 0.3588 - lr: 1.0000e-05\n",
      "Epoch 13/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2576 - mean_squared_error: 0.2576 - val_loss: 0.3658 - val_mean_squared_error: 0.3658 - lr: 1.0000e-05\n",
      "Epoch 14/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2563 - mean_squared_error: 0.2563 - val_loss: 0.3642 - val_mean_squared_error: 0.3642 - lr: 1.0000e-05\n",
      "Epoch 15/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2563 - mean_squared_error: 0.2563 - val_loss: 0.3700 - val_mean_squared_error: 0.3700 - lr: 1.0000e-05\n",
      "Epoch 16/25\n",
      "339/339 [==============================] - 12s 35ms/step - loss: 0.2566 - mean_squared_error: 0.2566 - val_loss: 0.3612 - val_mean_squared_error: 0.3612 - lr: 1.0000e-06\n",
      "Epoch 17/25\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 0.2536 - mean_squared_error: 0.2536 - val_loss: 0.3632 - val_mean_squared_error: 0.3632 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:31:19.062787: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_BiConv_term/assets\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('models/model_BiConv_term'):\n",
    "    # load previously trained model\n",
    "    model = k.models.load_model('models/model_BiConv_term')\n",
    "else:\n",
    "    # train model\n",
    "    model.fit(\n",
    "        train_sequences,\n",
    "        train_enrichment, \n",
    "        epochs = 25,\n",
    "        batch_size = 128,\n",
    "        validation_split = 0.1,\n",
    "        callbacks = [earlyStop, reduceLR],\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model.save('models/model_BiConv_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPYvWsbiKe3H"
   },
   "source": [
    "## Evalutate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEKj8hRVKe3H"
   },
   "source": [
    "Predict enrichment for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VyDBKAchKe3H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 09:31:20.038705: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-23 09:31:20.038764: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "predicted_enrichment = model.predict(np.stack(test_sequences))\n",
    "predicted_enrichment = pd.DataFrame(predicted_enrichment, columns = ['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI-rN-gnKe3I"
   },
   "source": [
    "Add predicted values to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w67kPl0DKe3I"
   },
   "outputs": [],
   "source": [
    "data_pred = pd.concat([data_test, predicted_enrichment], axis = 1).drop(columns = 'sequence')\n",
    "\n",
    "data_pred.to_csv('terminators_pred_BiConv.tsv', sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_test_N170+ACRs.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "60a8ad79298a54f79adb8b06e1239a4b712baef73c617213a454865c389ef0c1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
